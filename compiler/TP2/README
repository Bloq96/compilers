README file for Programming Assignment 2 (C++ edition)
=====================================================

Your directory should now contain the following files:

 Makefile        -> [course dir]/src/PA2/Makefile
 README
 cool.flex
 test.cl
 lextest.cc      -> [course dir]/src/PA2/lextest.cc
 mycoolc         -> [course dir]/src/PA2/mycoolc
 stringtab.cc    -> [course dir]/src/PA2/stringtab.cc
 utilities.cc    -> [course dir]/src/PA2/utilities.cc
 handle_flags.cc -> [course dir]/src/PA2/handle_flags.cc
 *.d             dependency files
 *.*             other generated files

The include (.h) files for this assignment can be found in 
[course dir]/include/PA2

	The Makefile contains targets for compiling and running your
	program. DO NOT MODIFY.

	The README contains this info. Part of the assignment is to fill
	the README with the write-up for your project. You should
	explain design decisions, explain why your code is correct, and
	why your test cases are adequate. It is part of the assignment
	to clearly and concisely explain things in text as well as to
	comment your code. Just edit this file.

	cool.flex is a skeleton file for the specification of the
	lexical analyzer. You should complete it with your regular
	expressions, patterns and actions. Information on how to do this
	is in the flex manual, which is part of your reader.

	test.cl is a COOL program that you can test the lexical
	analyzer on. It contains some errors, so it won't compile with
	coolc. However, test.cl does not exercise all lexical
	constructs of COOL and part of your assignment is to rewrite
	test.cl with a complete set of tests for your lexical analyzer.

	cool-parse.h contains definitions that are used by almost all parts
	of the compiler. DO NOT MODIFY.

	stringtab.{cc|h} and stringtab_functions.h contains functions
        to manipulate the string tables.  DO NOT MODIFY.

	utilities.{cc|h} contains functions used by the main() part of
	the lextest program. You may want to use the strdup() function
	defined in here. Remember that you should not print anything
	from inside cool.flex! DO NOT MODIFY.

	lextest.cc contains the main function which will call your
	lexer and print out the tokens that it returns.  DO NOT MODIFY.

	mycoolc is a shell script that glues together the phases of the
	compiler using Unix pipes instead of statically linking code.  
	While inefficient, this architecture makes it easy to mix and match
	the components you write with those of the course compiler.
	DO NOT MODIFY.	

        cool-lexer.cc is the scanner generated by flex from cool.flex.
        DO NOT MODIFY IT, as your changes will be overritten the next
        time you run flex.

 	The *.d files are automatically generated Makefiles that capture
 	dependencies between source and header files in this directory.
 	These files are updated automatically by Makefile; see the gmake
 	documentation for a detailed explanation.

Instructions
------------

	To compile your lextest program type:

	% gmake lexer

	Run your lexer by putting your test input in a file 'foo.cl' and
	run the lextest program:

	% ./lexer foo.cl

	To run your lexer on the file test.cl type:

	% gmake dotest

	If you think your lexical analyzer is correct and behaves like
	the one we wrote, you can actually try 'mycoolc' and see whether
	it runs and produces correct code for any examples.
	If your lexical analyzer behaves in an
	unexpected manner, you may get errors anywhere, i.e. during
	parsing, during semantic analysis, during code generation or
	only when you run the produced code on spim. So beware.

	To turnin your work type:

	% gmake submit-clean

	And run the "submit" program following the instructions on the
	course web page.
	
	Running "submit" will collect the files cool.flex, test.cl,
	README, and test.output. Don't forget to edit the README file to
	include your write-up, and to write your own test cases in
	test.cl.

 	You may turn in the assignment as many times as you like.
	However, only the last version will be retained for
	grading.

	If you change architectures you must issue

	% gmake clean

	when you switch from one type of machine to the other.
	If at some point you get weird errors from the linker,	
	you probably forgot this step.

	GOOD LUCK!

---8<------8<------8<------8<---cut here---8<------8<------8<------8<---

Write-up for PA2
----------------
- Códigos escritos

	O único arquivo modificado foi o cool.flex e o test.cl. Neles inicialmente foi provido
	um esqueleto de códio. Então à esse esqueleto foram adicionadas algumas funções 
	auxiliares bem como todas as definições necessárias para o lexer. As definições 
	de projeto as funções auxiliares serão explicadas abaixo.

	Todas as definições do lexer seguiram o manual do Lexer e o manual do cool e portanto
	não serão detalhadas.
	
	*Funções auxiliares*->

	int unscapeString(char *inputString, char *outputString, int length) = Copia uma string
	criando os caracteres escapadores. Por exemplo uma string composta por 'a''\\''n' será 
	transformada em 'a''\n'. Ela retornará a diferença de tamanho da nova string. Nesse exemplo
	retornará 1.

	*Decisões de projeto*->

	Para a definição das strings optou-se por usar 2 estados diferentes do inicial. O inicio da 
	identificação de uma string acontece com a leitura da aspas duplas ("\\""). Então o o lexer vai 
	para o estado \<STRING\>.
	Nesse estado todos os caracteres diferentes de "\n", "\0", EOF e "\\"" são adicionados a string. Caso
	receba outra aspas dupla ("\\"") a string é acabada e transformada em uma constante string usando
	a função `uscapeString`. Caso receba um "\n" a string termina de modo incorreto e portanto um erro 
	é gerado e o lex prossegue na linha seguinte. Caso receba um caractere null "\0" o lexer vai 
	para o estado \<END_STRING\> deve descartar todos os caracteres até encontrar uma nova linha, 
	um terminador de string ("\\"")	ou um fim de arquivo. Caso o lexer esteja no estado \<STRING\> e 
	receba um fim de arquivo, também é gerado um erro.

	Para o comentário foram consideradas duas situações. Para o comentário em linha, apenas uma 
	expressão regular expressa na variável RE_COMMENT foi o suficiente. Para o comentário com (* e *)
	também usou-se um estado diferente do estado inicial. Assim quando o lexer ler os caracteres "(*"
	ele vai para o estado \<COMMENT\> e descarta qualquer caractere subsequente exceto o fim de arquivo 
	(EOF) e o "*)". Caso
	o lexer leia um "*)" o comentário é terminado e o lexer volta para o estado inicial. Caso receba um
	EOF um erro é gerado com a mensagem "EOF in comment". Veja que fora do estado \<COMMENT\>, se o lexer 
	receber um "*)" um erro é gerado com a mensagem "Unmatched *)".

	Para tornar as keywords case insensitive, foi escrita uma expressão regular para cada keyword. 
	No caso das constantes true e false a primeira letra foi deixada minuscula.

	*Testes*

	Observação: para verificar se o lexer estava funcionado, utilizou-se, como base de comparação, a saída do lexer pré-compilado fornecido pelo professor para os testes com o parser.

	Além do teste base foram feitos alguns testes focados em pegar erros. Foram eles:

		1) Teste de mudança de case de todas as palavras reservadas: para isso, utilizou-se o script generateTokens.py.

		2) Teste com todos os caracteres avulsos:		
	(‘{‘,’}’,’(‘,’)’,’,’,’:’,’@’,’.’,’;’,’+’,’-’,’*’,’/’,’~’,’<’,’=’);

		3) Testes com diferentes inteiros;

		4) Teste com strings variados, incluindo algumas com caracteres precedidos de \;

			* No caso do ‘\n’ precedido de ‘\’, notou-se que o lexer do professor guardava o ‘\n’ como parte da string. Inicialmente, tínhamos considerado que esse ‘\n’ deveria ser descartado, porém acabamos o inserindo na string final para seguir o comportamento daquele do professor.

			* No caso da string com tamanho máximo, notou-se que, embora o valor máximo esteja definido como 1025, o lexer do professor retornava erro quando a string tinha exatamente 1025 caracteres (com uma exceção apenas). Então, embora tenhamos desenvolvido o lexer inicialmente para retornar erro apenas quando a string excedia 1025 caracteres, mudamos esse comportamento para ficar igual ao do professor, exceto no caso da exceção. A exceção a que nos referimos ocorre quando a string tem exatamente 1025 caracteres, porém termina em ‘\n’. Neste caso, o lexer do professor, retorna o erro ‘Unterminated string constant’, porém o nosso retorna ‘String constant too long’, pois em todos os outros casos, tanto o nosso lexer como o do professor, uma string de 1025 caracteres retorna ‘String constant too long’.

		5) Testes com comentários de uma linha (--) e de múltiplas linhas ((*...*));

		6) Teste com quase todas as situações de erro:
			* Caracteres inválidos;
			* Strings terminadas em ‘\n’;
			* Strings muito longas;
			* EOF presente em comentário multilinha;
			* Símbolos *) não casados.
			
		Não foram testados os erros string com caractere nulo, pois não sabíamos como gerar um \0; e string terminado em EOF, pois foi testado o EOF no caso de comentário. Além disso, para algumas máquinas, tanto o nosso lexer quanto o fornecido pelo professor geravam o erro ‘Unterminated string constant’ ao invés do ‘EOF in string constant’.